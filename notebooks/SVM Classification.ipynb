{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM) Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import init\n",
    "from common import constants as cn\n",
    "from common.trinary_data import TrinaryData\n",
    "from common.data_provider import DataProvider\n",
    "from common_python.plots import util_plots\n",
    "from plots import util_plots as xutil_plots\n",
    "from common_python.classifier import classifier_ensemble\n",
    "from common_python.classifier import classifier_collection\n",
    "from common_python.classifier.classifier_ensemble_random_forest import ClassifierEnsembleRandomForest\n",
    "\n",
    "import collections\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'is_normalize'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e266acc12a59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrinaryData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataProvider\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_normalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'is_normalize'"
     ]
    }
   ],
   "source": [
    "data = TrinaryData()\n",
    "data.df_X.head()\n",
    "dd = DataProvider(is_normalize=False)\n",
    "dd.do()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "Determine how many features to include."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess how many features should be included\n",
    "for filter in [10, 15, 20, 30]:\n",
    "    svm_ensemble = classifier_ensemble.ClassifierEnsemble(\n",
    "        classifier_ensemble.ClassifierDescriptorSVM(), filter_high_rank=filter, size=30)\n",
    "    df_X = data.df_X.copy()\n",
    "    df_X.columns = data.features\n",
    "    svm_ensemble.fit(df_X, data.ser_y)\n",
    "    # Analysis to determine how many features should be considered\n",
    "    svm_ensemble.plotImportance(title=\"%d\" % filter, ylim=[0, 1.5], ylabel=\"Parameter Value\")\n",
    "    #svm_ensemble.plotRank()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess Model Quality With Cross Validation\n",
    "Need to assess the hyperparameters: number of classifiers, number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcCVR(num_features, num_classifiers, num_iterations=10):\n",
    "     clf = classifier_ensemble.ClassifierEnsemble(\n",
    "         classifier_ensemble.ClassifierDescriptorSVM(),\n",
    "         filter_high_rank=num_features, size=num_classifiers)\n",
    "     return classifier_collection.ClassifierCollection.crossValidateByState(\n",
    "         clf, data.df_X, data.ser_y, num_iterations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calcCVR(5, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a bar plot for values of number of features and a fixed size of the classifiers\n",
    "def plotCVRFeatures(num_features, num_classifiers):\n",
    "    cvrs = [calcCVR(num_feature, num_classifiers) for num_feature in num_features]\n",
    "    yvals = [cvr.mean for cvr in cvrs]\n",
    "    stds = [cvr.std for cvr in cvrs]\n",
    "    #plt.errorbar(num_features, yvals, stds, marker='s', mfc='red',mec='green', ms=20, mew=4)\n",
    "    plt.errorbar(num_features, yvals, stds, marker='s')\n",
    "    plt.ylim(0,1)\n",
    "    plt.xlabel(\"NUMF\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"NUMC=%d\" % num_classifiers)\n",
    "#\n",
    "num_features1 = [12, 14]\n",
    "num_features2 = [120, 140]\n",
    "num_features1 = list(set(range(1,10)).union([5*v for v in range(3, 7)]))\n",
    "num_features2 = [100*v for v in range(1, 15)]\n",
    "for numfs in [num_features1, num_features2]:\n",
    "    for numc in [30, 100]:\n",
    "        plt.figure()\n",
    "        plotCVRFeatures(numfs, numc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = [lin_clf, lin_clf]\n",
    "classes = [0, 1, 2, 3, 4]\n",
    "def predict(df_X):\n",
    "    \"\"\" \n",
    "    Default prediction algorithm. Reports probability of each class.\n",
    "    :param pd.DataFrame: features, indexed by instance.\n",
    "    \"\"\"\n",
    "    # Change to an array of array of features\n",
    "    DUMMY_COLUMN = \"dummy_column\"\n",
    "    array = df_X.values\n",
    "    array = array.reshape(len(df_X), -1) \n",
    "    # Create a dataframe of class predictions\n",
    "    clf_predictions = [clf.predict(df_X) for clf in clfs]\n",
    "    instance_predictions = [dict(collections.Counter(x)) for x in zip(*clf_predictions)]\n",
    "    df = pd.DataFrame()\n",
    "    df[DUMMY_COLUMN] = np.repeat(-1, len(classes))\n",
    "    for idx, instance in enumerate(instance_predictions):\n",
    "        ser = pd.Series([x for x in instance.values()], index=instance.keys())\n",
    "        df[idx] = ser\n",
    "    del df[DUMMY_COLUMN]\n",
    "    df = df.applymap(lambda v: 0 if np.isnan(v) else v)\n",
    "    df = df / len(clfs)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.df_X.loc[[\"T5\", \"T10\", \"T20\"], :]\n",
    "predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicted_class = []\n",
    "for index in data.df_X.index:\n",
    "     predicted = lin_clf.predict(data.df_X.loc[[index],:])[0]\n",
    "     predicted_class.append(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predicting a class\n",
    "lin_clf.predict(data.df_X.loc[[\"T18\"],:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for n in range(5):\n",
    "    plt.figure()\n",
    "    plt.scatter(range(1515), lin_clf.coef_[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Analysis of rank of gene for multiple iterations of cross validations\n",
    "df_X = data.df_X.copy()\n",
    "for holdouts in [1, 2]:\n",
    "    df_X.columns = data.features\n",
    "    result = classifier_ensemble.LinearSVMEnsemble.crossValidate(df_X, data.ser_y,\n",
    "                                                                 iterations=500, holdouts=holdouts)\n",
    "    result.ensemble.plotRank(top=30, title=\"Holdouts: %d\" % holdouts, ylim=(0,160))\n",
    "    result.ensemble.plotImportance(top=30, title=\"Holdouts: %d\" % holdouts, ylim=(0, 0.02))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Random forest\n",
    "df_X = data.df_X.copy()\n",
    "df_X.columns = data.features\n",
    "ensemble = classifier_ensemble.RandomForestEnsemble(df_X, data.ser_y, num_iterations=20,\n",
    "                        n_estimators=5000, max_features=1500, random_state=0,\n",
    "                        min_samples_split=2, bootstrap=True)\n",
    "result.ensemble.plotRank(top=30, title=\"Random Forest\", ylim=(0,160))\n",
    "result.ensemble.plotImportance(top=30, title=\"Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "states = data.ser_y.unique().tolist()\n",
    "holdouts = 1\n",
    "result = classifier_ensemble.LinearSVMEnsemble.crossValidate(data.df_X, data.ser_y,\n",
    "    classifier_args={\"C\": 0.5}, iterations=500, holdouts=holdouts)\n",
    "for state in states:   \n",
    "    result.ensemble.plotRank(class_selection=state, top=20, title=\"State: %d\" % state, ylim=(0,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def evaluateRankFilter(high_rank,ylim=(-1,1), is_feature_columns=True):\n",
    "    states = data.ser_y.unique().tolist()\n",
    "    states.sort()\n",
    "    df_X = data.df_X.copy()\n",
    "    if is_feature_columns:\n",
    "        df_X.columns = data.features\n",
    "    holdouts = 1\n",
    "    result = classifier_ensemble.LinearSVMEnsemble.crossValidate(df_X, data.ser_y,\n",
    "        filter_high_rank=high_rank, iterations=500, holdouts=holdouts)\n",
    "    print(\"Accuracy: %f2.4 +/- %f2.4\"% (result.mean, result.std))\n",
    "    for state in states:   \n",
    "        result.ensemble.plotImportance(class_selection=state, top=high_rank, title=\"State: %d\" % state, ylim=ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateRankFilter(None, ylim=(-0.02, 0.02), is_feature_columns=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateRankFilter(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.mean, result.std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "1. Rv3574 is associated with lipid metabolism and virulence. Rv3573c is upregulated in state 2 (hypoxia). Maybe in the same regulon?\n",
    "1. There are many genes that are perfectly correlated with Rv3573c.\n",
    "1. Consider some kind of feature selection to reduce the number of parameters (since C regularization in SVM doesn't seem to work). Select based on rank variance for each classifier?\n",
    "1. KstR, Rv3574, is key to regulation in anoxia lipid metabolism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
