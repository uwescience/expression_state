{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of Lab Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (transform_data.py, line 46)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/home/ubuntu/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3265\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"<ipython-input-1-bcfdda293f61>\"\u001b[0m, line \u001b[1;32m3\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    from common.trinary_data import TrinaryData\n",
      "\u001b[0;36m  File \u001b[0;32m\"/home/ubuntu/xstate/xstate/python/common/trinary_data.py\"\u001b[0;36m, line \u001b[0;32m13\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    import common.transform_data as transform_data\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/home/ubuntu/xstate/xstate/python/common/transform_data.py\"\u001b[0;36m, line \u001b[0;32m46\u001b[0m\n\u001b[0;31m    provider.do()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "import init\n",
    "from common import constants as cn\n",
    "from common.trinary_data import TrinaryData\n",
    "from common.data_provider import DataProvider\n",
    "from common_python.plots import util_plots\n",
    "from common_python.classifier import classifier_ensemble\n",
    "from common_python.classifier import classifier_collection\n",
    "from common_python.classifier.classifier_ensemble_random_forest import ClassifierEnsembleRandomForest\n",
    "from common import transform_data\n",
    "\n",
    "import collections\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TrinaryData()\n",
    "data.df_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampleAM = transform_data.trinaryReadsDF(\n",
    "    csv_file=\"AM_MDM_Mtb_transcripts_DEseq.csv\")\n",
    "df_sampleAW = transform_data.trinaryReadsDF(\n",
    "\"AW_plus_v_AW_neg_Mtb_transcripts_DEseq.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_sampleAM = df_sampleAM.T\n",
    "df_sampleAM.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampleAW = df_sampleAW.T\n",
    "df_sampleAW.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Validations\n",
    "Classify T2-T25 and see if result is same as original class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider = DataProvider(is_normalize=False)\n",
    "provider.do()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTimeSample(time_index):\n",
    "    df0 = provider.dfs_data[0]\n",
    "    num = len(provider.dfs_data)\n",
    "    ser = pd.Series(np.repeat(0, len(df0.index)), index=df0.index)\n",
    "    for idx in range(num):\n",
    "        ser += provider.dfs_data[idx][time_index]\n",
    "    df = pd.DataFrame(ser/num)\n",
    "    df_result = transform_data.trinaryReadsDF(df_sample=df)\n",
    "    return df_result.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getTimeSample(2).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider.dfs_data[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_ensemble = classifier_ensemble.ClassifierEnsemble(\n",
    "        classifier_ensemble.ClassifierDescriptorSVM(), filter_high_rank=15, size=30)\n",
    "df_X = data.df_X.copy()\n",
    "df_X.columns = data.features\n",
    "svm_ensemble.fit(df_X, data.ser_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prediced_classesp = [svm_ensemble.predict(getTimeSample(n)) for n in [24, 25]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfff = pd.concat([dff, *prediced_classesp])\n",
    "dfff.index = range(2, 26)\n",
    "dfff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.concat(prediced_classes)\n",
    "dff.index = [2 + v for v in range(len(prediced_classes))]\n",
    "dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediced_classes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.ser_y\n",
    "df_expected = pd.DataFrame(data.ser_y)\n",
    "df_expected.columns = [\"columns\"]\n",
    "df_expected[\"values\"] = 1.0\n",
    "dff_expected = df_expected.pivot(columns=\"columns\", values=\"values\")\n",
    "dff_expected = dff_expected.fillna(0)\n",
    "dff_expected.index = [int(v[1:]) for v in dff_expected.index]\n",
    "dff_expected \n",
    "df_diff = (dff_expected - dfff)\n",
    "df_diff = df_diff.applymap(lambda v: np.abs(v))\n",
    "df_diff.sum().sum()/len(df_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of Lab Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_ensemble = classifier_ensemble.ClassifierEnsemble(\n",
    "        classifier_ensemble.ClassifierDescriptorSVM(), filter_high_rank=15, size=30)\n",
    "df_X = data.df_X.copy()\n",
    "df_X.columns = data.features\n",
    "svm_ensemble.fit(df_X, data.ser_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_ensemble.predict(df_sampleAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_ensemble.predict(df_sampleAW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparisons With Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_columns = [v+\"-\" for v in data.features]\n",
    "truncated_columns = [f[0:f.index(\"-\")] for f in dummy_columns]\n",
    "len(truncated_columns)\n",
    "df_X = data.df_X.copy()\n",
    "df_X.columns = truncated_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ClassifierEnsembleRandomForest(size=150, filter_high_rank=30)\n",
    "clf.fit(df_X, data.ser_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampleAM[truncated_columns].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(df_sampleAM[clf.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(df_sampleAW[truncated_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(clf.columns).difference(data.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = data.df_X.copy()\n",
    "df_X.columns = data.features\n",
    "df_X[clf.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcCVR(num_features, num_classifiers, num_iterations=10):\n",
    "     clf = ClassifierEnsembleRandomForest(\n",
    "         filter_high_rank=num_features, size=num_classifiers)\n",
    "     return classifier_collection.ClassifierCollection.crossValidateByState(\n",
    "         clf, df_X, data.ser_y, num_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calcCVR(30, 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
